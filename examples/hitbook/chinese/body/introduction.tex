\chapter{网络功能虚拟化}
网络对底层硬件的严重依赖，以及网络基础设施中各种专用硬件设备(如防火墙、深度包检测(DPI)设备和路由器)的存在，加剧了网络服务提供商面临的挑战。
此外，这些类型的硬件由于快速创新而缩短的生命周期往往会使资本支出和运营支出投资成倍增加[3]。
网络功能虚拟化技术是为了利用IT虚拟化的发展而发展起来的。
它将网络功能与底层专有硬件设备分开。
NFV是将网络功能从专用硬件设备转移到在商用现成(COTS)设备上运行的基于软件的应用程序的概念。
这些应用程序在大容量服务器、交换机和存储等标准IT平台上执行和整合。
通过NFV，可以根据网络需要在数据中心、网络节点和终端用户驻地等不同位置实例化网络功能[3]。
NFV为电信业提供了许多好处。
其中一些好处是平台的开放性、可扩展性和灵活性、运营性能改进、更短的开发周期以及更少的资本支出和运营支出投资[3]。

\chapter{网络功能虚拟化框架}
部署NFV的虚拟化平台的基本组件包括：·物理服务器：物理服务器是拥有CPU、存储和RAM等所有物理资源的裸机。
·虚拟机监控程序：虚拟机监控程序是运行和管理物理资源的软件。
它提供在其上执行来宾虚拟机的虚拟环境。
·来宾虚拟机：一款软件，用于模拟在其上执行所需应用程序的物理平台的体系结构和功能。
虚拟机(VM)部署在大容量服务器上，这些服务器可以位于数据中心、网络节点和最终用户设施中。
此外，大多数虚拟机使用云提供按需计算资源。
云计算服务以各种形式提供[4]：基础设施即服务(IaaS)，也称为硬件即服务(HAAS)、平台即服务(PaaS)、软件即服务(SaaS)和网络即服务(NAAS)。
对于NAAS的标准定义，目前还没有达成一致意见。
然而，它通常被认为是根据IaaS提供的。
NFV技术利用基础设施和网络服务(IaaS和NAAS)形成网络功能虚拟化基础设施(NFVI)[5]。
为了实现NFV承诺的目标，例如灵活地将虚拟网络功能(VNF)分配给硬件、快速服务创新、提高运营效率、降低功耗以及VNF之间开放的标准接口，每个VNF都应在包括VNF实例的动态启动和协调的框架上运行。
此外，它还应管理基于IT虚拟化技术的NFVI托管环境，以满足有关数据、资源分配、依赖性、可用性和其他属性的所有VNF要求。
ETSI NFV小组使用功能实体和参考点在功能级别定义了NFV架构框架，但没有任何具体实现的指示。
体系结构框架的功能实体和参考点在[5]中列出和定义，并在图2中显示。


\chapter{目前已有框架的放置方案}
建议的布局基于映射NFV框架实体以最适合虚拟环境。
Virtual Resources Manager、VNF Manager和Orchestrator已在虚拟机管理程序级别分组。
由于虚拟环境不仅将托管VNF，还将托管其他IT应用程序，因此此分组将导致集中式控制器。
提供NFVI即服务的基础架构在相同的硬件资源上同时提供云服务。
从本质上讲，虚拟机管理程序管理和协调虚拟化环境的物理和逻辑资源。
它能够感知正在使用底层硬件的虚拟机，并管理资源调度和决策，如迁移、资源扩展以及故障和故障恢复，从而更高效地满足VM(VNF和APP)的指定服务质量要求[5]。
虚拟化层由在虚拟机监控程序之上运行的跨平台虚拟资源管理器组成，以确保独立于虚拟机监控程序的VNF的可移植性和灵活性。
OpenStack、Eucalyptus、oVirt、OpenNebula和Nimbula都是跨平台虚拟层的例子[7]。
虚拟机托管VNF及其元件管理系统(EMS)。
每个VNF实例都有自己的专用EMS，以降低迁移现有VNF或启动新VNF时的复杂性。
具有VNF基础设施描述实体的运营和业务支持系统以集中形式部署，这提供了VNF软件映像的统一性，并最大限度地减少了数据库碎片。
建议的位置如图3所示。


\chapter{目前各行业应用情况}
服务提供商对NFV表现出了浓厚的兴趣。
注意到这种兴趣，电信设备供应商和IT公司已经开始调查NFV实现的不同方面。
领先的电信设备供应商，如爱立信、诺基亚、阿尔卡特朗讯和华为，已经开始采用和升级他们的设备以支持NFV[8，9]。
此外，提供运营商级软件的领先IT公司(如Wind River、6wind、Qosmos和HP)一直在与英特尔密切合作，在英特尔处理器上优化其软件，以实现更高的数据包处理计算量，从而在商业现成(COTS)平台上实现NFV和软件定义网络(SDN)。
英特尔发布了数据平面开发套件(DPDK)，并在其软件开发路线图中安排了信号处理开发套件的发布，以扩展和加快NFV和SDN的采用[10]。
服务提供商已经开始试验这些NFV产品，并对这些设备进行严格的测试，以确保它们将满足运营商级产品的期望[11]。

\chapter{网络功能虚拟化的挑战和需求}
尽管NFV对于电信服务提供商来说是一个很有前途的解决方案，但它面临着一些挑战，这些挑战可能会降低其性能，并阻碍其在电信行业的实施。
在本部分中，我们将讨论NFV的一些要求和挑战，以及建议的解决方案。
表1总结了这一部分

\chapter{各种特性}
\section{安全性}
安全是电信业的一个重要方面。
NFV应为网络功能获得接近专有托管环境的安全级别。
实现此安全级别的最佳方式是根据功能域进行划分。
通常可以根据以下功能域来定义安全性：1.虚拟化环境域(管理程序)2.计算域3.基础设施域(联网)4.当在虚拟化环境中实现网络功能时，预计应用域安全攻击会增加。
应使用受保护的虚拟机管理程序来防止任何未经授权的访问或数据泄露。
此外，其他进程(如数据通信和VM迁移)应在安全环境中运行[12]。
NFV使用应用编程接口(API)来提供与其基础设施的可编程编排和交互。
这些API给VNF带来了更高的安全威胁[13]。
表1列出了安全挑战和建议的解决方案。

\section{计算性能}
硬件服务器特性(如处理器体系结构、时钟频率、高速缓存大小、内存带宽和速度)的底层虚拟环境对VNF性能有深远影响。
VNF软件设计对VNF性能也起着重要作用。
VNF软件可以使用以下技术实现高性能：
1高要求的VNF应该使用多线程技术，并以分布式和可扩展的方式实现，以便在多核或不同主机上执行。
2软件实例应具有独立的内存结构，以避免操作系统死锁。
3 VNF应该实现自己的网络堆栈，避免在操作系统中实现网络堆栈，这会消耗大量的计算资源。
4应尽可能使用对输入/输出接口的直接访问，以减少延迟并增加数据吞吐量。
5应使用处理器亲和性技术来利用高速缓冲存储器。
在VNF软件中实施这些技术可能需要与IT环境中当前使用的给定服务器池中的自动资源分配不同的方法

\section{虚拟网络功能内部之间的连接}
与通过直接连接或通过第2层(L2)交换机互连网络功能的经典方法不同，虚拟化环境使用不同的方法。
在虚拟化环境中，虚拟机可以在不同的场景中连接[14]：1.如果两个VNF位于相同的物理服务器和相同的本地接入网络(LAN)上，则它们将通过相同的vSwitch连接。
2.如果两个VNF位于同一物理服务器但不同的LAN上，则连接将通过第一个vSwitch到达网络接口控制器(NIC)，然后到达外部交换机，然后再回到同一个NIC。
此网卡将连接转发到第二个LAN的vSwitch，然后转发到VNF。
3.如果两个VNF位于不同的服务器上，则连接将通过第一个vSwitch到达NIC，然后到达外部交换机。
此交换机将连接转发到所需服务器的网卡。
最后，此NIC将其转发到其内部vSwitch，然后转发到目标VNF。
某些网卡提供从虚拟机的直接访问。
这些NIC与单根I/O虚拟化(SR-IOV)兼容。
它们为虚拟机提供更快、更高的吞吐量。
每种连接技术在性能、灵活性和隔离性方面都有自己的优势。
与SR-IOV兼容NIC提供的虚拟接口相比，虚拟机管理程序管理的虚拟接口的性能较低。
但是，虚拟机管理程序提供的虚拟接口更易于配置，并且以更简单的方式支持虚拟机实时迁移。
正确的选择取决于VNF工作负载。

\section{可移植性}
虚拟化的网络功能可以以不同的方式部署，每种方式都有自己的优点和缺点。
直接在裸机上执行的虚拟化网络功能可确保可预测的性能，因为软件实例到硬件的映射是可预测的。
这种部署牺牲了资源隔离，并使软件实例安全难以实现，因为多个软件设备作为进程在同一操作系统上执行。
此外，设计的软件将依赖于操作系统。
通过虚拟环境部署虚拟网络功能可提高可移植性，并确保VNF统一查看硬件资源。
此部署还使每个VNF能够在其特定操作系统上执行，而无需了解底层操作系统。
此外，由于VNF在由虚拟机管理程序层管理的独立虚拟机上执行，因此确保了VNF资源隔离，从而保证了它们之间不会发生意外交互。
应该使用严格的资源映射来保证资源隔离。

\chapter{网络功能虚拟化的运营和管理}
虚拟网络功能应该在编排管理系统中实现为简单的拖放操作。
要实现这一点，应该使用支持自动化管理的标准模板来描述VNF和计算基础设施。
编排管理系统负责通过北向和南向交互提供和管理NFV环境。
北向交互用于管理和提供对VNF的访问。
此外，VNF可以使用它们获取信息或请求查询，例如请求更多的计算资源。
南向交互用于与NFVI交互，并向其他框架实体请求信息。
此外，它们还用于请求有关策略、VNF软件映像、VNF描述和网络转发图的信息。

\chapter{网络功能虚拟化与传统网络的共存性}
虚拟网络功能应该能够与传统网络设备共存。
这意味着： ·它应该能够在对现有网络影响最小的情况下与传统管理系统交互。
·网络转发图不应因存在一个或多个VNF而受到影响。
·应确保VNF实例和物理功能之间的安全过渡，不会造成任何服务中断或性能影响[15]。

\chapter{保证运营商级服务}
运营商级服务是一种硬件、软件和系统组件确保高可用性和可靠性的服务。
NFV要满足运营商级服务要求，应提供故障恢复能力、服务连续性和服务保证。
通过在NFV框架中实施自动按需机制以在故障后重建VNF来提供对故障的恢复能力。
VNF重构不应对系统造成任何影响，以确保稳定服务。
服务保证由NFV协调器提供，它几乎实时监控网络功能性能并扩展资源[16]。

\chapter{用例和服务}
NFV技术原则上通过定义明确的标准考虑虚拟化的所有网络功能。
最有可能的是，NFV服务将以类似于IT虚拟化服务模式的方式提供。
NFV服务模式包括NFVI即服务(NFVIaaS)、VNF即服务(VNFaaS)和虚拟网络平台即服务(VNPaaS)。
服务提供商将在这些服务模式之间进行选择，以满足其网络连接需求和使用案例。
例如，一些使用案例将包括固定接入网络功能虚拟化、内容交付网络虚拟化和家庭环境虚拟化[17]

\chapter{移动网络虚拟化}
随着需要始终连接的移动设备和应用的数量不断增加，移动网络连接需求也在迅速增长。
服务运营商必须不断升级和增强其基础设施，例如，通过提供足够的移动基站和网络核心来实现所需的数据吞吐量、延迟和服务质量。
移动网络虚拟化的目标是移动网络基站和移动核心网。
服务提供商已经表现出对虚拟化移动基站的兴趣，以便他们可以根据需要在标准硬件中整合尽可能多的网络功能，以利用单个虚拟化的移动基站来服务不同的移动网络技术。
移动基站的虚拟化具有挑战性，因为它在其物理层托管信号处理功能。
因此，首先考虑在更高的网络堆栈层实施虚拟化。
考虑到eNodeB是第四代网络(长期演进，LTE)基站，虚拟化将在第三层实施，然后在第二层实施[17]。
第3层托管连接到移动核心网络的控制和数据平面的功能。
第2层承载分组数据融合协议(PDCP)、无线链路控制(RLC)和媒体访问控制(MAC)网络功能。
通过虚拟化基站的第2层和第3层，可以为多个基站提供集中式计算基础设施，从而降低基站成本，因为只应在现场实施基带信号处理。
此外，服务提供商将受益于共享他们的远程基站基础设施，以最小的资本支出和运营成本投资实现更好的区域覆盖。
还有一些努力集中了几个基站的L1功能[18]。
他们将能够升级VNF以支持多种电信技术，并使其适应新版本。


\chapter{演进的网络核心数据包虚拟化}
在众多接入技术中，移动核心网是网络中最重要的组成部分。
虚拟化核心内的功能是NFV的主要目标。
最新的核心网络是演进分组核心(EPC)网络。
EPC是在版本8中作为简化的全IP核心网络体系结构引入的。
它旨在通过结合先进的IP基础设施和移动性来实现移动宽带服务。
此外，EPC旨在支持多种接入技术[19]。
连接需求的快速增长导致服务提供商在其移动核心网络基础设施中进行了超出财务意义的更多资本支出和运营支出投资。
从这一点开始，拥有一个灵活、健壮且易于管理的网络变得至关重要；一个可以按需实时扩展且易于管理的网络。
虚拟化EPC为服务提供商提供了所有这些好处。
在LTE中支持IP连接的基本EPC实体如下：1.移动性管理实体(MME)是LTE网络中的主要控制平面实体。
2.服务网关(SGW)负责将用户数据分组路由和转发到基站。
3.分组数据网络网关(PDN-GW)(PGW)确保用户数据平面与外部网络之间的连通性。
4.归属用户服务器(HSS)是中央用户信息数据库。
5.策略和计费规则功能(PCRF)负责对每个业务和用户的策略和计费进行实时传递和决策。


\chapter{在NFV环境中对EPC实体进行分组}
实施虚拟化EPC(VEPC)是电信设备供应商的主要目标。
由于EPC包含多个功能，因此在云中实例化VNF对性能有很大影响；因此，根据VNF的交互和工作负载将其分组在一起。
通常，根据工作负载在一台物理服务器或一个本地网络中实例化每个组是有益的。
本文提出了一种可以提高性能的vEPC实体分组方法。
该方法基于分析vEPC实体的互连和功能，以实现较少的控制信令流量和较少的数据平面拥塞。
提出的方法保持了平面架构和控制平面与数据平面解耦的两个EPC原则。
分组方法将实体分为四个部分。
下面列出了这些数据，汇总在表2中，并在图5中进行了说明。
由于了解LTE框架对于真正掌握提议分组的好处是必要的，因此我们根据需要描述每个实体的功能。
有关LTE架构的全面研究，请参阅[19]。

\chapter{分段}
\section{分段一}
在建议的分组中，MME与HSS前端(HSS FE)一起迁移。
HSS FE是实现HSS的所有逻辑功能但不包含用户信息数据库的应用。
通过使用MME实施HSS FE，身份验证和授权过程在内部执行，而无需通过网络进行任何数据交易。
HSS FE确保与MME进行的所有交互就好像MME正在访问完整的HSS数据库一样。
HSS FE从作为中央用户信息数据库的用户数据储存库(UDR)发出对用户信息数据的查询，并将这些数据临时存储在高速缓冲存储器中。
在查询用户信息后，HSS FE充当一个完整的用户数据库，并执行与MME实体的所有鉴权和授权过程。
图4示出了将用户设备附连到LTE网络的过程。
由于HSS FE在一个查询[20]中获得所有所需信息，因此该分组最小化了认证用户所必须执行的网络事务的数量。
此外，UDR和HSS FE之间的通信通过轻量级目录访问协议(LDAP)进行，而不是Diameter信令协议。
LDAP是用于通过IP网络交换和管理分布式目录信息服务的应用协议。
对于数据库信息查询，LDAP是比Diameter更有效的协议[20]。
它也更快，需要更少的资源[20，21]。
它使用传输层安全(TLS)或安全套接字层(SSL)保护信息交换，而Diameter信令使用网际协议安全(IPsec)连接进行信息交换。
与IPsec相比，TLS/SSL需要更少的计算资源，并且需要更少的启动和恢复时间。
此外，TLS和SSL是在虚拟化平台上提供更好灵活性的应用层安全协议[22]。


\section{分段二}
在建议的分组中，服务通用分组无线业务(GPRS)支持节点(SGSN)与归属位置寄存器前端(HLR FE)一起迁移。
SGSN是一个服务实体，其功能与组合的MME和SGW几乎相同。
SGSN是存在于GPRS核心网络中的网络功能实体，其允许移动网络(2G、3G)向外部网络发送IP分组。
它负责向移动基站发送数据包和从移动基站发送数据包。
SGSN具有用户数据平面功能，例如管理数据包路由和传输。
此外，它还具有移动性管理、逻辑链路管理以及身份验证和计费功能等控制平面功能。
在建议的方法中假设SGSN，因为几乎所有服务提供商除了其4G网络之外，还支持2G和3G网络。
SGSN不与任何EPC实体组合，因为SGSN具有控制和数据平面，这与EPC架构解耦原则相冲突。
HLR是保存全球移动通信系统(GSM)核心网络中的用户信息的数据库。
HLR FE与SGSN合并的原因几乎与MME与HSS FE合并的原因相同。
此外，这种组合实现了统一的数据库，并支持现有SGSN与EPC系统的Gn接口的组合。
Gn接口基于GPRS隧道协议(GTP)。

\section{分段三}
在建议的分组中，PGW与SGW一起迁移。
这两个数据平面实体的合并遵循平面架构原则，以最小化数据平面处理节点的数量。
在一个虚拟机或VNF中实施这两个实体将受益于数据平面中的集中处理，并有助于克服处理和网络瓶颈。
在此网段中，用户数据在由SGW提供服务后不会路由或传输到PGW。
相反，网段可以直接访问PGW，PGW将其路由到外部网络。
虚拟化环境中的集中处理使应用程序能够应用CPU关联过程，从而高效地使用CPU高速缓存。
此外，这种合并还避免了通过虚拟交换机进行不必要的路由，这是虚拟环境中的一个主要瓶颈。
为了满足PGW和SGW所需的延迟和服务质量，还可以使用直接网络接口访问实现更高的VNF数据吞吐量。
除了消除SGW和PGW之间的信令事务流量外，此迁移还可实现更好的数据监控和计费。
所有信令事务都在内部执行。

\section{分段四}
在建议的分组中，迁移了UDR、PCRF、在线计费系统(OCS)和离线计费系统(OFCS)。
使UDR与PCRF一起迁移导致从用户信息高效地生成策略功能，因为PCRF请求用户信息为每个建立的承载生成所需的策略。
此方法可防止信息交换使网络节点不堪重负，将策略功能生成的延迟降至最低，并加快了对PGW的策略实施。
至于OCS和OFCS，OCS用于向网络用户实时收费，就像在预付费信用系统中一样，而OFCS用于在会话结束后向用户收费，就像在被称为“随用随付”的计费服务中一样。
OCS和OFCS与PCRF和PCEF交互，以收集有关会话的信息，并对PGW实施计费策略，例如在超过信用限制时终止通信会话。
此外，此部分将需要与OSS/BSS交互的所有实体组合在一起。
限制OSS/BSS交互的分段可以更有效地控制网络服务。
在这种分组方法中，所有网段几乎全部通过GPRS隧道协议(GTP)连接，而不是通过Diameter协议接口。
尽管Diameter协议是EPC实体的控制平面中的增强型信令协议，但它依赖于其传输层中的流控制传输协议(SCTP)和传输控制协议(TCP)。
众所周知，当交换少量数据时，SCTP和TCP会降低网络性能[23]。
这些网络降级是由于发送用于建立连接的控制分组(例如确认分组)造成的。
当数据包较小时，通常，当数据包较大时，它们需要更多的计算资源来传输相同数量的数据。
GTP在其传输层中依赖于用户数据报协议(UDP)，该协议在小分组数据交换连接上具有令人满意的性能[23]。
由于控制信令数据包较小，因此使用在GTP上维护接口的方法可以提高计算性能和网络资源利用率。
虽然建议的分组在最小化控制信令流量以避免网络基础设施拥塞方面带来了好处，但它需要很大的计算能力，因为大多数事务都是在内部执行的。

\section{定量分析}
建议分组的主要目的是减少EPC中的控制信令流量，预计到2015年，EPC中的控制信令流量将呈指数级增长[24]。
为了说明建议的分组优势，应用了[25]中生成的信令流量，并估计了所需带宽的减少。
在[25]中，连接到EPC实体的15个eNB产生了信令话务，其中话务概况和规划参数如表3所示。然而，在[25]中，MME和HSS之间的总信令事务话务量为1039,430个事务，MME和HSS之间的平均每秒事务数为每个用户6.2个事务。
使用建议的MME和HSS FE分组，每个订户的事务数量从6.2个减少到1个。
事务数量减少背后的原因是将所有用户信息组合到来自UDR[25]的一个查询中。
因此，总交易流量降至173,239个交易/秒。在[25]中，SGW和PGW之间的信令交易流量为56,559个交易。
使用建议的SGW和PGW分组，消除了网络上的信令事务。
此外，PCRF的总信令事务流量为37,706，在[25]中每个承载平均有两个事务。
因此，PCRF和UDR信令交易数量为18,853个。
由于80\%的用户拥有预付费账户，PCRF和OCS之间产生了30,164笔交易。
使用建议的分组，这些事务被消除，因为PCRF、OCS和UDR在同一网段中实施。
信令流量在这些实体和PCEF之间进行，PCEF在不同的网段中使用PGW实施。
这些结果如表4所示。